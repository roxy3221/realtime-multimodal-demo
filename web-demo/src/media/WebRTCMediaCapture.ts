/**
 * WebRTCMediaCapture - åŸºäºWebRTCçš„å¢å¼ºåª’ä½“é‡‡é›†
 * è§£å†³æ‘„åƒå¤´é»‘å±ã€éŸ³é¢‘è´¨é‡å’Œè®¾å¤‡ç®¡ç†é—®é¢˜
 */

import type { FaceEvent, ProsodyEvent, MediaConfig } from '../types';
import { EventBus } from '../events/EventBus';
import { DEFAULT_MEDIA_CONFIG } from '../config/defaults';
import { WebSpeechASR } from '../asr/WebSpeechASR';

export class WebRTCMediaCapture {
  private peerConnection: RTCPeerConnection | null = null;
  private localStream: MediaStream | null = null;
  private externalVideoElement: HTMLVideoElement | null = null;
  private audioContext: AudioContext | null = null;
  private audioWorklet: AudioWorkletNode | null = null;
  private videoWorker: Worker | null = null;
  private videoCanvas: OffscreenCanvas | null = null;
  private videoCanvasContext: OffscreenCanvasRenderingContext2D | null = null;
  private frameProcessingRate = 15; // FPS for face detection
  private videoWorkerReady = false; // æ·»åŠ Workerå°±ç»ªçŠ¶æ€
  private asr: WebSpeechASR | null = null;
  private eventBus: EventBus;
  private isCapturing = false;
  private animationFrame: number | null = null;

  // WebRTCå¢å¼ºåŠŸèƒ½
  private deviceManager: RTCDeviceManager;

  constructor(eventBus: EventBus) {
    this.eventBus = eventBus;
    this.deviceManager = new RTCDeviceManager();
  }

  /**
   * åˆå§‹åŒ–WebRTCåª’ä½“é‡‡é›†
   */
  async initialize(config: Partial<MediaConfig> = {}): Promise<void> {
    const finalConfig = {
      ...DEFAULT_MEDIA_CONFIG,
      ...config
    };

    try {
      console.log('ğŸš€ Initializing WebRTC MediaCapture...');
      
      // 1. è®¾ç½®WebRTCè¿æ¥ï¼ˆæœ¬åœ°å¤„ç†ç”¨ï¼‰
      await this.setupWebRTCConnection();
      
      // 2. è·å–ä¼˜åŒ–åçš„åª’ä½“æµ
      await this.setupEnhancedMediaStream(finalConfig);
      
      // 3. åˆå§‹åŒ–éŸ³é¢‘å¤„ç†ç®¡é“ï¼ˆWebRTCå¢å¼ºï¼‰
      await this.setupEnhancedAudioPipeline(finalConfig);
      
      // 4. åˆå§‹åŒ–è§†é¢‘å¤„ç†ç®¡é“
      await this.setupVideoPipeline(finalConfig);
      
      // 5. åˆå§‹åŒ–ASR
      this.setupASR();
      
      console.log('âœ… WebRTC MediaCapture initialized successfully');
    } catch (error) {
      console.error('âŒ WebRTC MediaCapture initialization failed:', error);
      throw this.createDetailedError(error);
    }
  }

  /**
   * è®¾ç½®WebRTCè¿æ¥ï¼ˆç”¨äºæœ¬åœ°éŸ³è§†é¢‘ä¼˜åŒ–ï¼‰
   */
  private async setupWebRTCConnection(): Promise<void> {
    // åˆ›å»ºPeerConnectionï¼ˆæœ¬åœ°å¤„ç†ä¸éœ€è¦ICEæœåŠ¡å™¨ï¼‰
    this.peerConnection = new RTCPeerConnection({
      iceServers: [] // æœ¬åœ°å¤„ç†
    });

    // ç›‘å¬è¿æ¥çŠ¶æ€
    this.peerConnection.onconnectionstatechange = () => {
      console.log('WebRTC Connection State:', this.peerConnection?.connectionState);
    };

    // ç›‘å¬ICEè¿æ¥çŠ¶æ€
    this.peerConnection.oniceconnectionstatechange = () => {
      console.log('ICE Connection State:', this.peerConnection?.iceConnectionState);
    };
  }

  /**
   * è·å–WebRTCä¼˜åŒ–çš„åª’ä½“æµ
   */
  private async setupEnhancedMediaStream(config: MediaConfig): Promise<void> {
    try {
      // æ£€æŸ¥ navigator.mediaDevices æ˜¯å¦å¯ç”¨
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('MediaDevices API not available. Please use HTTPS or localhost.');
      }

      // å…ˆæ£€æŸ¥å¯ç”¨è®¾å¤‡ï¼ˆæ·»åŠ é”™è¯¯å¤„ç†ï¼‰
      let devices;
      try {
        devices = await this.deviceManager.enumerateDevices();
        console.log('Available devices:', devices);
      } catch (deviceError) {
        console.warn('âš ï¸ Device enumeration failed:', deviceError);
        // ç»§ç»­æ‰§è¡Œï¼Œä¸è®©è®¾å¤‡æšä¸¾å¤±è´¥é˜»æ­¢æ•´ä¸ªæµç¨‹
      }

      // WebRTCä¼˜åŒ–çš„çº¦æŸ
      const enhancedConstraints: MediaStreamConstraints = {
        video: {
          width: { ideal: config.video.width },
          height: { ideal: config.video.height },
          frameRate: { ideal: config.video.frameRate },
          facingMode: config.video.facingMode,
          // WebRTCè§†é¢‘å¢å¼º
          aspectRatio: { ideal: 4/3 }
        },
        audio: {
          // WebRTCéŸ³é¢‘å¢å¼º - å…³é”®æ”¹è¿›
          sampleRate: { ideal: 48000 }, // æå‡é‡‡æ ·ç‡
          channelCount: { exact: 1 },
          echoCancellation: true,       // å›å£°æ¶ˆé™¤
          noiseSuppression: true,       // å™ªå£°æŠ‘åˆ¶  
          autoGainControl: true,        // è‡ªåŠ¨å¢ç›Š
          googEchoCancellation: true,   // Googleå¢å¼ºå›å£°æ¶ˆé™¤
          googAutoGainControl: true,    // Googleè‡ªåŠ¨å¢ç›Š
          googNoiseSuppression: true,   // Googleå™ªå£°æŠ‘åˆ¶
          googHighpassFilter: true,     // é«˜é€šæ»¤æ³¢
          googTypingNoiseDetection: true // é”®ç›˜å™ªéŸ³æ£€æµ‹
        } as any // å…è®¸Googleç‰¹å®šçº¦æŸ
      };

      this.localStream = await navigator.mediaDevices.getUserMedia(enhancedConstraints);
      
      // æ³¨æ„ï¼šä¸åˆ›å»ºå†…éƒ¨videoå…ƒç´ ï¼Œä½¿ç”¨å¤–éƒ¨æä¾›çš„å…ƒç´ 
      
      // æ·»åŠ åˆ°PeerConnectionï¼ˆå¯ç”¨WebRTCå¤„ç†ï¼‰
      this.localStream.getTracks().forEach(track => {
        this.peerConnection?.addTrack(track, this.localStream!);
      });
      
      // ç­‰å¾…æµå‡†å¤‡å°±ç»ªï¼ˆå¦‚æœæœ‰å¤–éƒ¨videoå…ƒç´ ï¼‰
      if (this.externalVideoElement) {
        await new Promise<void>((resolve) => {
          if (this.externalVideoElement!.readyState >= 2) {
            resolve();
          } else {
            this.externalVideoElement!.onloadedmetadata = () => {
              console.log('âœ… WebRTC Video stream ready:', {
                width: this.externalVideoElement!.videoWidth,
                height: this.externalVideoElement!.videoHeight
              });
              resolve();
            };
          }
        });
      }

      // éªŒè¯éŸ³é¢‘è½¨é“è´¨é‡
      const audioTrack = this.localStream.getAudioTracks()[0];
      if (audioTrack) {
        const settings = audioTrack.getSettings();
        console.log('âœ… WebRTC Audio settings:', settings);
      }

    } catch (error) {
      console.error('âŒ Enhanced media stream setup failed:', error);
      throw error;
    }
  }

  /**
   * è®¾ç½®WebRTCå¢å¼ºçš„éŸ³é¢‘å¤„ç†ç®¡é“
   */
  private async setupEnhancedAudioPipeline(config: MediaConfig): Promise<void> {
    if (!this.localStream) throw new Error('Stream not initialized');

    const audioTrack = this.localStream.getAudioTracks()[0];
    if (!audioTrack) {
      console.warn('âš ï¸ No audio track available');
      return;
    }

    // åˆ›å»ºé«˜é‡‡æ ·ç‡AudioContext
    this.audioContext = new AudioContext({
      sampleRate: 48000, // WebRTCä¼˜åŒ–é‡‡æ ·ç‡
      latencyHint: 'interactive'
    });

    // åŠ è½½å¢å¼ºçš„AudioWorkletå¤„ç†å™¨
    await this.audioContext.audioWorklet.addModule('/workers/enhanced-audio-processor.js');
    
    // åˆ›å»ºWebRTCä¼˜åŒ–çš„åª’ä½“æº
    const source = this.audioContext.createMediaStreamSource(this.localStream);
    
    this.audioWorklet = new AudioWorkletNode(this.audioContext, 'enhanced-audio-processor', {
      numberOfInputs: 1,
      numberOfOutputs: 0,
      channelCount: 1,
      processorOptions: {
        sampleRate: 48000,
        windowSize: config.audio.windowSize || 2048, // å¢å¤§çª—å£æå‡è´¨é‡
        useWebRTCEnhancements: true
      }
    });

    // ç›‘å¬å¢å¼ºçš„éŸµå¾‹äº‹ä»¶
    this.audioWorklet.port.onmessage = (event) => {
      const { type, data } = event.data;
      
      switch (type) {
        case 'enhanced-prosody-event':
          this.eventBus.publish({
            type: 'prosody',
            t: Date.now(),
            deltaScore: data.deltaScore,
            rms: data.rms,
            f0: data.f0, // WebRTCå¤„ç†åæ›´ç¨³å®šçš„F0
            wpm: data.wpm || 0
          } as ProsodyEvent);
          break;
          
        case 'webrtc-vad-change':
          console.log('WebRTC VADçŠ¶æ€å˜åŒ–:', data);
          break;
          
        case 'audio-data':
          // WebSpeechASRç›´æ¥ä½¿ç”¨éº¦å…‹é£è¾“å…¥ï¼Œä¸éœ€è¦å‘é€éŸ³é¢‘æ•°æ®
          // ä¿ç•™æ­¤å¤„ç†å™¨ä»¥å¤‡å°†æ¥ä½¿ç”¨å…¶ä»–ASRæœåŠ¡
          break;
      }
    };

    // è¿æ¥éŸ³é¢‘ç®¡é“
    source.connect(this.audioWorklet);
    
    console.log('âœ… Enhanced WebRTC audio pipeline initialized');
  }

  /**
   * è®¾ç½®è§†é¢‘å¤„ç†ç®¡é“ï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
   */
  private async setupVideoPipeline(config: MediaConfig): Promise<void> {
    try {
      // åˆ›å»º MediaPipe é¢éƒ¨è¯†åˆ« Worker
      this.videoWorker = new Worker('/workers/mediapipe-face-detector.js');
      
      // è®¾ç½®ç”»å¸ƒç”¨äºå¸§æ•è·ï¼ˆä¼˜åŒ–æ€§èƒ½ï¼‰
      this.videoCanvas = new OffscreenCanvas(config.video.width, config.video.height);
      this.videoCanvasContext = this.videoCanvas.getContext('2d', { 
        willReadFrequently: true,  // ä¼˜åŒ–é¢‘ç¹è¯»å–æ€§èƒ½
        alpha: false              // ç¦ç”¨é€æ˜åº¦ä»¥æå‡æ€§èƒ½
      });
      
      this.frameProcessingRate = config.video.frameRate || 15;
      
      // åˆå§‹åŒ– Worker
      this.videoWorker.postMessage({
        type: 'init',
        data: {
          config: {
            width: config.video.width,
            height: config.video.height,
            processingRate: this.frameProcessingRate
          }
        }
      });

      // ç›‘å¬ Worker æ¶ˆæ¯
      this.videoWorker.onmessage = (event) => {
        const { type, data } = event.data;
        
        switch (type) {
          case 'face-event':
            this.eventBus.publish({
              type: 'face',
              t: Date.now(),
              deltaScore: data.deltaScore,
              expr: data.expr,
              pose: data.pose
            } as FaceEvent);
            break;
            
          case 'status':
            if (data.initialized) {
              this.videoWorkerReady = true;
              console.log('âœ… Face detection worker ready');
            }
            console.log('ğŸ­ Face detection worker status:', data);
            break;
            
          case 'error':
            console.error('âŒ Face detection worker error:', data);
            this.videoWorkerReady = false;
            break;
        }
      };
      
      console.log('âœ… Video pipeline with MediaPipe initialized');
    } catch (error) {
      console.error('âŒ Video pipeline setup failed:', error);
      throw error;
    }
  }

  /**
   * è®¾ç½®ASR
   */
  private setupASR(): void {
    this.asr = new WebSpeechASR(this.eventBus);
  }

  /**
   * å¼€å§‹é‡‡é›†
   */
  async startCapture(): Promise<void> {
    if (this.isCapturing) return;
    
    this.isCapturing = true;
    
    // å¯åŠ¨éŸ³é¢‘ä¸Šä¸‹æ–‡
    if (this.audioContext?.state === 'suspended') {
      await this.audioContext.resume();
    }
    
    // å¯åŠ¨ASR
    if (this.asr) {
      this.asr.start();
    }
    
    // å¯åŠ¨è§†é¢‘å¸§å¤„ç†å¾ªç¯
    this.startVideoFrameLoop();
    
    console.log('ğŸ¥ WebRTC Media capture started');
  }

  /**
   * çœŸå®è§†é¢‘å¸§å¤„ç†å¾ªç¯
   */
  private startVideoFrameLoop(): void {
    if (!this.isCapturing || !this.videoWorker || !this.externalVideoElement) return;

    let lastFrameTime = 0;
    const frameInterval = 1000 / this.frameProcessingRate; // ms per frame

    const processFrame = (currentTime: number) => {
      if (!this.isCapturing || !this.videoWorker || !this.externalVideoElement) return;

      // åªåœ¨ Worker å‡†å¤‡å°±ç»ªæ—¶å¤„ç†å¸§
      if (this.videoWorkerReady && currentTime - lastFrameTime >= frameInterval) {
        this.captureAndProcessFrame();
        lastFrameTime = currentTime;
      }

      // ä¸‹ä¸€å¸§
      this.animationFrame = requestAnimationFrame(processFrame);
    };

    this.animationFrame = requestAnimationFrame(processFrame);
  }

  /**
   * æ•è·å¹¶å¤„ç†å½“å‰è§†é¢‘å¸§
   */
  private captureAndProcessFrame(): void {
    if (!this.externalVideoElement || !this.videoCanvasContext || !this.videoCanvas) return;
    
    const video = this.externalVideoElement;
    
    // æ£€æŸ¥è§†é¢‘æ˜¯å¦å‡†å¤‡å°±ç»ª
    if (video.readyState < 2 || video.videoWidth === 0 || video.videoHeight === 0) {
      return;
    }
    
    try {
      // ç»˜åˆ¶å½“å‰è§†é¢‘å¸§åˆ°ç”»å¸ƒ
      this.videoCanvasContext.drawImage(video, 0, 0, this.videoCanvas.width, this.videoCanvas.height);
      
      // è·å–å›¾åƒæ•°æ®
      const imageData = this.videoCanvasContext.getImageData(0, 0, this.videoCanvas.width, this.videoCanvas.height);
      
      // å‘é€å¸§æ•°æ®åˆ° Worker å¤„ç†
      this.videoWorker?.postMessage({
        type: 'process-frame',
        data: {
          imageData,
          timestamp: performance.now()
        }
      });
    } catch (error) {
      console.warn('âš ï¸ Frame capture failed:', error);
    }
  }

  /**
   * åœæ­¢é‡‡é›†
   */
  stopCapture(): void {
    this.isCapturing = false;
    
    if (this.animationFrame) {
      cancelAnimationFrame(this.animationFrame);
      this.animationFrame = null;
    }
    
    if (this.asr) {
      this.asr.stop();
    }
    
    console.log('â¹ï¸ WebRTC Media capture stopped');
  }

  /**
   * è®¾ç½®å¤–éƒ¨è§†é¢‘å…ƒç´ ï¼ˆç”¨äºé¢„è§ˆï¼‰
   */
  setExternalVideoElement(videoElement: HTMLVideoElement): void {
    this.externalVideoElement = videoElement;
  }
  
  /**
   * è·å–é¢„è§ˆå…ƒç´ 
   */
  getPreviewElement(): HTMLVideoElement | null {
    return this.externalVideoElement;
  }

  /**
   * è·å–åª’ä½“æµ
   */
  getStream(): MediaStream | null {
    return this.localStream;
  }

  /**
   * è·å–åª’ä½“æµçŠ¶æ€
   */
  getStatus() {
    return {
      isCapturing: this.isCapturing,
      hasVideo: !!this.localStream?.getVideoTracks().length,
      hasAudio: !!this.localStream?.getAudioTracks().length,
      audioContextState: this.audioContext?.state,
      webrtcConnectionState: this.peerConnection?.connectionState
    };
  }

  /**
   * åˆ›å»ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
   */
  private createDetailedError(error: any): Error {
    if (error.name === 'NotAllowedError') {
      return new Error('æ‘„åƒå¤´/éº¦å…‹é£æƒé™è¢«æ‹’ç»ã€‚è¯·å…è®¸è®¿é—®å¹¶åˆ·æ–°é¡µé¢ã€‚');
    } else if (error.name === 'NotFoundError') {
      return new Error('æœªæ‰¾åˆ°æ‘„åƒå¤´æˆ–éº¦å…‹é£è®¾å¤‡ã€‚');
    } else if (error.name === 'NotReadableError') {
      return new Error('è®¾å¤‡è¢«å…¶ä»–åº”ç”¨ç¨‹åºå ç”¨ã€‚');
    } else if (error.message?.includes('MediaDevices API not available')) {
      return new Error('éœ€è¦ HTTPS è¿æ¥æ‰èƒ½è®¿é—®æ‘„åƒå¤´å’Œéº¦å…‹é£ã€‚è¯·ä½¿ç”¨ https://localhost æˆ–éƒ¨ç½²åˆ° HTTPS æœåŠ¡å™¨ã€‚');
    }
    return error;
  }

  /**
   * é‡Šæ”¾èµ„æº
   */
  dispose(): void {
    this.stopCapture();
    
    if (this.localStream) {
      this.localStream.getTracks().forEach(track => track.stop());
    }
    
    if (this.peerConnection) {
      this.peerConnection.close();
    }
    
    if (this.audioContext) {
      this.audioContext.close();
    }
    
    if (this.videoWorker) {
      this.videoWorker.terminate();
    }
  }
}

/**
 * WebRTCè®¾å¤‡ç®¡ç†å™¨
 */
class RTCDeviceManager {
  async enumerateDevices() {
    try {
      if (!navigator.mediaDevices || !navigator.mediaDevices.enumerateDevices) {
        throw new Error('mediaDevices.enumerateDevices not supported');
      }
      
      const devices = await navigator.mediaDevices.enumerateDevices();
      return {
        videoInputs: devices.filter(d => d.kind === 'videoinput'),
        audioInputs: devices.filter(d => d.kind === 'audioinput'),
        audioOutputs: devices.filter(d => d.kind === 'audiooutput')
      };
    } catch (error) {
      console.error('Device enumeration failed:', error);
      // è¿”å›ç©ºè®¾å¤‡åˆ—è¡¨ï¼Œè®©åº”ç”¨ç»§ç»­è¿è¡Œ
      return {
        videoInputs: [],
        audioInputs: [],
        audioOutputs: []
      };
    }
  }
}