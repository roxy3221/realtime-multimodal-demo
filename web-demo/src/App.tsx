import { useState, useEffect, useRef } from 'react';
import { checkBrowserSupport } from './utils';
import { globalEventBus } from './events/EventBus';
import { WebRTCMediaCapture } from './media/WebRTCMediaCapture';
import type { MultiModalEvent } from './types';
import './App.css';

function App() {
  const [isSupported, setIsSupported] = useState(false);
  const [, setEvents] = useState([] as MultiModalEvent[]);
  const [isInitialized, setIsInitialized] = useState(false);
  const [isCapturing, setIsCapturing] = useState(false);
  const [mediaStatus, setMediaStatus] = useState({
    hasVideo: false,
    hasAudio: false,
    audioContextState: 'suspended' as AudioContextState,
    webrtcConnectionState: 'new' as RTCPeerConnectionState
  });
  
  // æ–°å¢çŠ¶æ€
  const [faceMetrics, setFaceMetrics] = useState({
    headPose: { yaw: 0, pitch: 0 },
    expression: { type: 'ä¸­æ€§', confidence: 0 },
    eyeState: { state: 'æ­£å¸¸', ear: 0.30 },
    faceStability: { state: 'ç¨³å®š', score: 100 }
  });
  
  const [speechMetrics, setSpeechMetrics] = useState({
    frequency: { value: 0, change: 0 },
    energy: { value: 0.00, activity: 'é™é»˜' },
    wpm: { value: 0, zeroCrossing: 0.0 },
    quality: { state: 'æ­£å¸¸', spectralCentroid: 0 }
  });
  
  const [features, setFeatures] = useState({
    faceDetection: false,
    prosodyAnalysis: false,
    realtimeChart: false
  });

  // ASRçŠ¶æ€
  const [transcriptText, setTranscriptText] = useState('');
  const [currentWPM, setCurrentWPM] = useState(0);
  
  const mediaCaptureRef = useRef<WebRTCMediaCapture | null>(null);
  const videoPreviewRef = useRef<HTMLVideoElement | null>(null);

  useEffect(() => {
    // æ£€æŸ¥æµè§ˆå™¨æ”¯æŒ
    const support = checkBrowserSupport();
    const criticalSupported = support.webWorkers && support.broadcastChannel;
    setIsSupported(criticalSupported);

    console.log('ğŸ” Browser support check:', support);
    if (!criticalSupported) {
      console.warn('âš ï¸ Some features may not work due to browser limitations');
    }

    if (criticalSupported) {
      // åˆå§‹åŒ–WebRTCMediaCapture
      mediaCaptureRef.current = new WebRTCMediaCapture(globalEventBus);
      
      // è®¢é˜…æ‰€æœ‰äº‹ä»¶ç”¨äºè°ƒè¯•å’ŒUIæ›´æ–°
      const unsubscribe = globalEventBus.subscribe('all', (event) => {
        // setEvents(prev => [...prev.slice(-9), event]); // ä¿ç•™æœ€è¿‘10ä¸ªäº‹ä»¶
        
        // æ ¹æ®äº‹ä»¶ç±»å‹æ›´æ–°UIæ•°æ®
        if (event.type === 'face') {
          console.log('ğŸ­ Face event received:', event);
          setFaceMetrics({
            headPose: {
              yaw: event.pose.yaw,
              pitch: event.pose.pitch
            },
            expression: {
              type: String(event.expr.type || 'ä¸­æ€§'),
              confidence: Math.round((event.expr.confidence || 0) * 100)
            },
            eyeState: {
              state: String(event.expr.type) === 'ç–²åŠ³' ? 'ç–²åŠ³' : 'æ­£å¸¸',
              ear: event.expr.ear || 0.30
            },
            faceStability: {
              state: event.deltaScore > 0.6 ? 'ä¸ç¨³å®š' : 'ç¨³å®š',
              score: Math.round((1 - event.deltaScore) * 100)
            }
          });
        }
        
        if (event.type === 'prosody') {
          // WebRTCä¼˜åŒ–çš„prosodyäº‹ä»¶å¤„ç†
          const enhancedEvent = event as any; // åŒ…å«WebRTCå¢å¼ºå­—æ®µ
          
          setSpeechMetrics({
            frequency: {
              value: Math.round(enhancedEvent.f0 || 0), // æ ¼å¼åŒ–ä¸ºæ•´æ•°Hz
              change: enhancedEvent.f0Stability ? Math.round((1 - enhancedEvent.f0Stability) * 100) : 0
            },
            energy: {
              value: Number((enhancedEvent.rms || 0).toFixed(3)), // 3ä½å°æ•°
              activity: enhancedEvent.vadActive ? 'è¯´è¯ä¸­' : 'é™é»˜'
            },
            wpm: {
              value: enhancedEvent.wpm || 0,
              zeroCrossing: Number((enhancedEvent.zeroCrossingRate || 0).toFixed(2))
            },
            quality: {
              state: (enhancedEvent.f0Confidence > 0.5) ? 'æ­£å¸¸' : 'ä¸ç¨³å®š',
              spectralCentroid: Math.round(enhancedEvent.spectralCentroid || 0)
            }
          });
        }

        if (event.type === 'asr') {
          // æ›´æ–°è½¬å½•æ–‡æœ¬
          setTranscriptText(prev => prev + event.textDelta + ' ');
          
          // æ›´æ–°è¯­é€Ÿ
          if (event.currentWPM !== undefined) {
            setCurrentWPM(event.currentWPM);
            setSpeechMetrics(prev => ({
              ...prev,
              wpm: {
                value: event.currentWPM || 0,
                zeroCrossing: prev.wpm.zeroCrossing
              }
            }));
          }
        }
      });

      setIsInitialized(true);

      return () => {
        unsubscribe();
        if (mediaCaptureRef.current) {
          mediaCaptureRef.current.dispose();
        }
      };
    }
  }, []);

  const handleStartDemo = async () => {
    if (!mediaCaptureRef.current) return;
    
    try {
      console.log('ğŸš€ Starting WebRTC multimodal demo...');
      
      // WebRTCåˆå§‹åŒ–ï¼ˆåŒ…å«è®¾å¤‡æ£€æŸ¥å’Œä¼˜åŒ–ï¼‰
      await mediaCaptureRef.current.initialize();
      
      // è®¾ç½®è§†é¢‘é¢„è§ˆ
      const previewElement = mediaCaptureRef.current.getPreviewElement();
      if (previewElement && videoPreviewRef.current) {
        // ç›´æ¥è®¾ç½®srcObjectè€Œä¸æ˜¯ä»previewElementè·å–
        const stream = previewElement.srcObject as MediaStream;
        if (stream) {
          videoPreviewRef.current.srcObject = stream;
          
          // å¼ºåˆ¶æ’­æ”¾è§†é¢‘
          videoPreviewRef.current.onloadeddata = () => {
            console.log('âœ… WebRTC video preview ready');
            if (videoPreviewRef.current) {
              videoPreviewRef.current.play().catch(e => {
                console.warn('Video play failed, this is normal for autoplay restrictions:', e);
              });
            }
          };
          
          // æ·»åŠ é”™è¯¯å¤„ç†
          videoPreviewRef.current.onerror = (e) => {
            console.error('âŒ Video preview error:', e);
          };
        } else {
          console.warn('âš ï¸ No media stream found in preview element');
        }
      }
      
      // å¼€å§‹é‡‡é›†
      await mediaCaptureRef.current.startCapture();
      
      // æ›´æ–°çŠ¶æ€
      setIsCapturing(true);
      const status = mediaCaptureRef.current.getStatus();
      setMediaStatus({
        hasVideo: status.hasVideo,
        hasAudio: status.hasAudio,
        audioContextState: status.audioContextState || 'suspended',
        webrtcConnectionState: status.webrtcConnectionState || 'new'
      });
      
      console.log('âœ… Demo started successfully');
    } catch (error) {
      console.error('âŒ Demo start failed:', error);
      alert(`å¯åŠ¨å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  };

  const handleStopDemo = () => {
    if (!mediaCaptureRef.current) return;
    
    mediaCaptureRef.current.stopCapture();
    setIsCapturing(false);
    const status = mediaCaptureRef.current.getStatus();
    setMediaStatus({
      hasVideo: status.hasVideo,
      hasAudio: status.hasAudio,
      audioContextState: status.audioContextState || 'suspended',
      webrtcConnectionState: status.webrtcConnectionState || 'new'
    });
    
    console.log('â¹ï¸ Demo stopped');
  };

  const handleReset = () => {
    setFaceMetrics({
      headPose: { yaw: 0, pitch: 0 },
      expression: { type: 'ä¸­æ€§', confidence: 0 },
      eyeState: { state: 'æ­£å¸¸', ear: 0.30 },
      faceStability: { state: 'ç¨³å®š', score: 100 }
    });
    
    setSpeechMetrics({
      frequency: { value: 0, change: 0 },
      energy: { value: 0.00, activity: 'é™é»˜' },
      wpm: { value: 0, zeroCrossing: 0.0 },
      quality: { state: 'æ­£å¸¸', spectralCentroid: 0 }
    });
    
    setEvents([]);
    setTranscriptText('');
    setCurrentWPM(0);
  };

  const toggleFeature = (feature: keyof typeof features) => {
    setFeatures(prev => ({
      ...prev,
      [feature]: !prev[feature]
    }));
  };

  if (!isSupported) {
    return (
      <div className="app">
        <h1>âš ï¸ æµè§ˆå™¨åŠŸèƒ½å—é™</h1>
        <p>éƒ¨åˆ†é«˜çº§åŠŸèƒ½å¯èƒ½æ— æ³•ä½¿ç”¨ï¼Œä½†æ‚¨ä»å¯ä»¥æŸ¥çœ‹ç•Œé¢æ¼”ç¤ºã€‚å»ºè®®ä½¿ç”¨æœ€æ–°ç‰ˆChromeã€Firefoxæˆ–Edgeå¹¶å¯ç”¨HTTPSã€‚</p>
        <details>
          <summary>è¯¦ç»†æ”¯æŒæƒ…å†µ</summary>
          <pre>{JSON.stringify(checkBrowserSupport(), null, 2)}</pre>
        </details>
        <p style={{ marginTop: '20px' }}>
          <button onClick={() => setIsSupported(true)} style={{ 
            padding: '10px 20px', 
            background: '#4CAF50', 
            color: 'white', 
            border: 'none', 
            borderRadius: '5px' 
          }}>
            ä»è¦ç»§ç»­æŸ¥çœ‹ç•Œé¢
          </button>
        </p>
      </div>
    );
  }

  return (
    <div className="app">
      <header className="app-header">
        <h1>ğŸ¯ å®æ—¶å¤šæ¨¡æ€åˆ†ææ¼”ç¤º</h1>
        <p>åŸºäºäº‹ä»¶é©±åŠ¨æ¶æ„çš„æ™ºèƒ½è§¦å‘ç³»ç»Ÿ</p>
      </header>

      <main className="app-main">
        {/* é¡¶éƒ¨åˆ†æé¢æ¿åŒºåŸŸ */}
        <div className="analysis-panels">
          {/* å·¦ä¾§é¢æ¿ï¼šè§†é¢‘é‡‡é›†ä¸é¢éƒ¨åˆ†æ */}
          <div className="video-analysis-panel">
            <div className="panel-title">è§†é¢‘é‡‡é›†ä¸é¢éƒ¨åˆ†æ</div>
            
            <div className="video-preview">
              <video 
                ref={videoPreviewRef}
                autoPlay
                muted
                playsInline
                className="preview-video"
              />
              <div className="video-overlay">
                {!isCapturing && <div>ç‚¹å‡»å¼€å§‹é¢„è§ˆ</div>}
              </div>
              <div className={`connection-status ${mediaStatus.hasVideo ? 'connected' : ''}`}>
                {mediaStatus.hasVideo ? 'å·²è¿æ¥' : 'æœªè¿æ¥'}
              </div>
            </div>
            
            <div className="face-metrics">
              <div className="metric-item">
                <div className="metric-value">{faceMetrics.headPose.yaw}Â°, {faceMetrics.headPose.pitch}Â°</div>
                <div className="metric-label">åèˆªè§’, ä¿¯ä»°è§’</div>
              </div>
              <div className="metric-item">
                <div className="metric-value">{faceMetrics.expression.type}</div>
                <div className="metric-label">ç½®ä¿¡åº¦: {faceMetrics.expression.confidence}%</div>
              </div>
              <div className="metric-item">
                <div className="metric-value">{faceMetrics.eyeState.state}</div>
                <div className="metric-label">EAR: {faceMetrics.eyeState.ear.toFixed(2)}</div>
              </div>
              <div className="metric-item">
                <div className="metric-value">{faceMetrics.faceStability.state}</div>
                <div className="metric-label">å¾—åˆ†: {faceMetrics.faceStability.score}%</div>
              </div>
            </div>
          </div>
          
          {/* å³ä¾§é¢æ¿ï¼šè¯­éŸ³è¯†åˆ«ä¸éŸµå¾‹åˆ†æ */}
          <div className="speech-analysis-panel">
            <div className="panel-title">è¯­éŸ³è¯†åˆ«ä¸éŸµå¾‹åˆ†æ</div>
            
            <div className={`speech-input-status ${speechMetrics.energy.activity === 'è¯´è¯ä¸­' ? 'listening' : ''}`}>
              {speechMetrics.energy.activity === 'è¯´è¯ä¸­' ? 'æ­£åœ¨è¯†åˆ«è¯­éŸ³...' : 'ç­‰å¾…è¯­éŸ³è¾“å…¥...'}
            </div>
            
            <div className="speech-metrics">
              <div className="metric-item">
                <div className="metric-value">{speechMetrics.frequency.value}</div>
                <div className="metric-label">å˜åŒ–: Â±{speechMetrics.frequency.change}</div>
              </div>
              <div className="metric-item">
                <div className="metric-value">{speechMetrics.energy.value.toFixed(2)}</div>
                <div className="metric-label">æ´»åŠ¨: {speechMetrics.energy.activity}</div>
              </div>
              <div className="metric-item">
                <div className="metric-value">{speechMetrics.wpm.value}</div>
                <div className="metric-label">è¿‡é›¶ç‡: {speechMetrics.wpm.zeroCrossing.toFixed(1)}</div>
              </div>
              <div className="metric-item">
                <div className="metric-value">{speechMetrics.quality.state}</div>
                <div className="metric-label">é¢‘è°±é‡å¿ƒ: {speechMetrics.quality.spectralCentroid} Hz</div>
              </div>
            </div>
            
            {/* å®æ—¶è½¬å½•æ˜¾ç¤º */}
            <div className="transcript-display">
              <div className="transcript-title">å®æ—¶è¯­éŸ³è½¬å½•</div>
              <div className="transcript-content">
                {transcriptText || 'ç­‰å¾…è¯­éŸ³è¾“å…¥...'}
              </div>
              <div className="transcript-stats">
                å½“å‰è¯­é€Ÿ: {currentWPM} WPM
              </div>
            </div>
            
            {/* å®æ—¶å›¾è¡¨åŒºåŸŸ */}
            <div className="chart-container">
              <div className="chart-title">å®æ—¶å›¾è¡¨</div>
              <div className="chart-axes">æ—¶é—´</div>
              <div className="chart-legend">
                <div className="legend-item">
                  <div className="legend-color frequency"></div>
                  <span>åŸºé¢‘ (Hz)</span>
                </div>
                <div className="legend-item">
                  <div className="legend-color energy"></div>
                  <span>èƒ½é‡</span>
                </div>
              </div>
            </div>
          </div>
        </div>

        {/* æ§åˆ¶æŒ‰é’®åŒºåŸŸ */}
        <div className="controls">
          {!isCapturing ? (
            <button 
              className="start-button"
              onClick={handleStartDemo}
              disabled={!isInitialized}
            >
              å¼€å§‹åˆ†æ
            </button>
          ) : (
            <button 
              className="stop-button"
              onClick={handleStopDemo}
            >
              åœæ­¢åˆ†æ
            </button>
          )}
          <button 
            className="reset-button"
            onClick={handleReset}
          >
            é‡ç½®
          </button>
        </div>

        {/* åŠŸèƒ½å¼€å…³åŒºåŸŸ */}
        <div className="feature-toggles">
          <div className="toggles-container">
            <div className="toggle-item">
              <span className="toggle-label">å¯ç”¨é¢éƒ¨æ£€æµ‹</span>
              <div 
                className={`toggle-switch ${features.faceDetection ? 'active' : ''}`}
                onClick={() => toggleFeature('faceDetection')}
              ></div>
            </div>
            <div className="toggle-item">
              <span className="toggle-label">å¯ç”¨éŸµå¾‹åˆ†æ</span>
              <div 
                className={`toggle-switch ${features.prosodyAnalysis ? 'active' : ''}`}
                onClick={() => toggleFeature('prosodyAnalysis')}
              ></div>
            </div>
            <div className="toggle-item">
              <span className="toggle-label">æ˜¾ç¤ºå®æ—¶å›¾è¡¨</span>
              <div 
                className={`toggle-switch ${features.realtimeChart ? 'active' : ''}`}
                onClick={() => toggleFeature('realtimeChart')}
              ></div>
            </div>
          </div>
        </div>
      </main>
    </div>
  );
}

export default App;
